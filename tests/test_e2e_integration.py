"""End-to-end integration tests for Voice Text Processor.

This module tests the complete workflow from input to storage,
including audio processing, text processing, and error scenarios.

Requirements: All requirements (end-to-end validation)
"""

import os
import json
import pytest
import tempfile
import shutil
from pathlib import Path
from unittest.mock import patch, AsyncMock, MagicMock
from io import BytesIO
from fastapi.testclient import TestClient


@pytest.fixture
def temp_data_dir():
    """Create a temporary directory for test data."""
    temp_dir = tempfile.mkdtemp()
    yield temp_dir
    # Close all logging handlers before cleanup to release file handles
    import logging
    for handler in logging.root.handlers[:]:
        handler.close()
        logging.root.removeHandler(handler)
    # Give Windows time to release file handles
    import time
    time.sleep(0.1)
    try:
        shutil.rmtree(temp_dir)
    except PermissionError:
        # On Windows, sometimes files are still locked - ignore cleanup errors
        pass


@pytest.fixture
def test_client(temp_data_dir):
    """Create a test client with temporary data directory."""
    # Reset config
    import app.config
    app.config._config = None
    
    with patch.dict(os.environ, {
        "ZHIPU_API_KEY": "test_key_1234567890",
        "DATA_DIR": temp_data_dir,
        "LOG_FILE": str(Path(temp_data_dir) / "test.log")
    }, clear=True):
        from app.main import app
        with TestClient(app) as client:
            yield client


class TestAudioToStorageE2E:
    """End-to-end tests for audio processing workflow.
    
    Tests: éŸ³é¢‘ä¸Šä¼  â†’ ASR â†’ è¯­ä¹‰è§£æ â†’ å­˜å‚¨ â†’ å“åº”
    """
    
    @patch("app.main.ASRService")
    @patch("app.main.SemanticParserService")
    def test_complete_audio_workflow_with_all_data(
        self, 
        mock_parser_class, 
        mock_asr_class, 
        test_client,
        temp_data_dir
    ):
        """Test complete audio workflow: upload â†’ ASR â†’ parsing â†’ storage â†’ response.
        
        This test validates the entire pipeline with all data types present.
        """
        # Mock ASR service
        mock_asr = MagicMock()
        mock_asr.transcribe = AsyncMock(
            return_value="ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼Œæƒ³åˆ°ä¸€ä¸ªæ–°é¡¹ç›®æƒ³æ³•ï¼Œæ˜å¤©è¦å®ŒæˆæŠ¥å‘Š"
        )
        mock_asr.close = AsyncMock()
        mock_asr_class.return_value = mock_asr
        
        # Mock semantic parser with complete data
        from app.models import MoodData, InspirationData, TodoData, ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="å¼€å¿ƒ", intensity=8, keywords=["æ„‰å¿«", "æ”¾æ¾"]),
            inspirations=[
                InspirationData(core_idea="æ–°é¡¹ç›®æƒ³æ³•", tags=["åˆ›æ–°", "æŠ€æœ¯"], category="å·¥ä½œ")
            ],
            todos=[
                TodoData(task="å®ŒæˆæŠ¥å‘Š", time="æ˜å¤©", location="åŠå…¬å®¤")
            ]
        ))
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Create fake audio file
        audio_data = b"fake audio content for testing"
        files = {"audio": ("test.mp3", BytesIO(audio_data), "audio/mpeg")}
        
        # Make request
        response = test_client.post("/api/process", files=files)
        
        # Verify response
        assert response.status_code == 200
        data = response.json()
        
        # Check response structure
        assert "record_id" in data
        assert "timestamp" in data
        assert data["mood"]["type"] == "å¼€å¿ƒ"
        assert data["mood"]["intensity"] == 8
        assert len(data["inspirations"]) == 1
        assert data["inspirations"][0]["core_idea"] == "æ–°é¡¹ç›®æƒ³æ³•"
        assert len(data["todos"]) == 1
        assert data["todos"][0]["task"] == "å®ŒæˆæŠ¥å‘Š"
        
        # Verify ASR was called
        mock_asr.transcribe.assert_called_once()
        
        # Verify semantic parser was called with transcribed text
        mock_parser.parse.assert_called_once_with(
            "ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼Œæƒ³åˆ°ä¸€ä¸ªæ–°é¡¹ç›®æƒ³æ³•ï¼Œæ˜å¤©è¦å®ŒæˆæŠ¥å‘Š"
        )
        
        # Verify storage - check all JSON files
        records_file = Path(temp_data_dir) / "records.json"
        moods_file = Path(temp_data_dir) / "moods.json"
        inspirations_file = Path(temp_data_dir) / "inspirations.json"
        todos_file = Path(temp_data_dir) / "todos.json"
        
        # Check records.json
        assert records_file.exists()
        with open(records_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        assert len(records) == 1
        assert records[0]["record_id"] == data["record_id"]
        assert records[0]["input_type"] == "audio"
        assert records[0]["original_text"] == "ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼Œæƒ³åˆ°ä¸€ä¸ªæ–°é¡¹ç›®æƒ³æ³•ï¼Œæ˜å¤©è¦å®ŒæˆæŠ¥å‘Š"
        
        # Check moods.json
        assert moods_file.exists()
        with open(moods_file, 'r', encoding='utf-8') as f:
            moods = json.load(f)
        assert len(moods) == 1
        assert moods[0]["record_id"] == data["record_id"]
        assert moods[0]["type"] == "å¼€å¿ƒ"
        
        # Check inspirations.json
        assert inspirations_file.exists()
        with open(inspirations_file, 'r', encoding='utf-8') as f:
            inspirations = json.load(f)
        assert len(inspirations) == 1
        assert inspirations[0]["record_id"] == data["record_id"]
        assert inspirations[0]["core_idea"] == "æ–°é¡¹ç›®æƒ³æ³•"
        
        # Check todos.json
        assert todos_file.exists()
        with open(todos_file, 'r', encoding='utf-8') as f:
            todos = json.load(f)
        assert len(todos) == 1
        assert todos[0]["record_id"] == data["record_id"]
        assert todos[0]["task"] == "å®ŒæˆæŠ¥å‘Š"

    @patch("app.main.ASRService")
    @patch("app.main.SemanticParserService")
    def test_audio_workflow_with_partial_data(
        self, 
        mock_parser_class, 
        mock_asr_class, 
        test_client,
        temp_data_dir
    ):
        """Test audio workflow with only some data types present."""
        # Mock ASR service
        mock_asr = MagicMock()
        mock_asr.transcribe = AsyncMock(return_value="ä»Šå¤©æ„Ÿè§‰å¾ˆå¹³é™")
        mock_asr.close = AsyncMock()
        mock_asr_class.return_value = mock_asr
        
        # Mock semantic parser with only mood (no inspirations or todos)
        from app.models import MoodData, ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="å¹³é™", intensity=5, keywords=["å®‰é™"])
        ))
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Create fake audio file
        audio_data = b"fake audio content"
        files = {"audio": ("test.wav", BytesIO(audio_data), "audio/wav")}
        
        # Make request
        response = test_client.post("/api/process", files=files)
        
        # Verify response
        assert response.status_code == 200
        data = response.json()
        assert data["mood"]["type"] == "å¹³é™"
        assert len(data["inspirations"]) == 0
        assert len(data["todos"]) == 0
        
        # Verify storage - only records.json and moods.json should exist
        records_file = Path(temp_data_dir) / "records.json"
        moods_file = Path(temp_data_dir) / "moods.json"
        inspirations_file = Path(temp_data_dir) / "inspirations.json"
        todos_file = Path(temp_data_dir) / "todos.json"
        
        assert records_file.exists()
        assert moods_file.exists()
        assert not inspirations_file.exists()
        assert not todos_file.exists()
    
    @patch("app.main.ASRService")
    @patch("app.main.SemanticParserService")
    def test_audio_workflow_with_multiple_items(
        self, 
        mock_parser_class, 
        mock_asr_class, 
        test_client,
        temp_data_dir
    ):
        """Test audio workflow with multiple inspirations and todos."""
        # Mock ASR service
        mock_asr = MagicMock()
        mock_asr.transcribe = AsyncMock(
            return_value="æœ‰ä¸‰ä¸ªæƒ³æ³•å’Œä¸¤ä¸ªä»»åŠ¡è¦åš"
        )
        mock_asr.close = AsyncMock()
        mock_asr_class.return_value = mock_asr
        
        # Mock semantic parser with multiple items
        from app.models import InspirationData, TodoData, ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            inspirations=[
                InspirationData(core_idea="æƒ³æ³•1", tags=["æ ‡ç­¾1"], category="å·¥ä½œ"),
                InspirationData(core_idea="æƒ³æ³•2", tags=["æ ‡ç­¾2"], category="ç”Ÿæ´»"),
                InspirationData(core_idea="æƒ³æ³•3", tags=["æ ‡ç­¾3"], category="å­¦ä¹ ")
            ],
            todos=[
                TodoData(task="ä»»åŠ¡1", time="ä»Šå¤©", location="å®¶é‡Œ"),
                TodoData(task="ä»»åŠ¡2", time="æ˜å¤©", location="å…¬å¸")
            ]
        ))
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Create fake audio file
        audio_data = b"fake audio content"
        files = {"audio": ("test.m4a", BytesIO(audio_data), "audio/m4a")}
        
        # Make request
        response = test_client.post("/api/process", files=files)
        
        # Verify response
        assert response.status_code == 200
        data = response.json()
        assert len(data["inspirations"]) == 3
        assert len(data["todos"]) == 2
        
        # Verify storage
        inspirations_file = Path(temp_data_dir) / "inspirations.json"
        todos_file = Path(temp_data_dir) / "todos.json"
        
        with open(inspirations_file, 'r', encoding='utf-8') as f:
            inspirations = json.load(f)
        assert len(inspirations) == 3
        
        with open(todos_file, 'r', encoding='utf-8') as f:
            todos = json.load(f)
        assert len(todos) == 2


class TestTextToStorageE2E:
    """End-to-end tests for text processing workflow.
    
    Tests: æ–‡æœ¬æäº¤ â†’ è¯­ä¹‰è§£æ â†’ å­˜å‚¨ â†’ å“åº”
    """
    
    @patch("app.main.SemanticParserService")
    def test_complete_text_workflow_with_all_data(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test complete text workflow: submit â†’ parsing â†’ storage â†’ response.
        
        This test validates the entire pipeline for text input with all data types.
        """
        # Mock semantic parser with complete data
        from app.models import MoodData, InspirationData, TodoData, ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="ç„¦è™‘", intensity=6, keywords=["ç´§å¼ ", "æ‹…å¿ƒ"]),
            inspirations=[
                InspirationData(core_idea="è§£å†³æ–¹æ¡ˆ", tags=["é—®é¢˜è§£å†³"], category="å·¥ä½œ")
            ],
            todos=[
                TodoData(task="å‡†å¤‡ä¼šè®®", time="ä¸‹åˆ3ç‚¹", location="ä¼šè®®å®¤"),
                TodoData(task="å‘é€é‚®ä»¶", time="ä»Šæ™š", location=None)
            ]
        ))
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Make request with text
        text_input = "æœ‰ç‚¹ç„¦è™‘ï¼Œæƒ³åˆ°ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼Œä¸‹åˆè¦å‡†å¤‡ä¼šè®®ï¼Œä»Šæ™šè¦å‘é€é‚®ä»¶"
        response = test_client.post(
            "/api/process",
            data={"text": text_input}
        )
        
        # Verify response
        assert response.status_code == 200
        data = response.json()
        
        # Check response structure
        assert "record_id" in data
        assert "timestamp" in data
        assert data["mood"]["type"] == "ç„¦è™‘"
        assert data["mood"]["intensity"] == 6
        assert len(data["inspirations"]) == 1
        assert len(data["todos"]) == 2
        
        # Verify semantic parser was called with input text
        mock_parser.parse.assert_called_once_with(text_input)
        
        # Verify storage - check all JSON files
        records_file = Path(temp_data_dir) / "records.json"
        moods_file = Path(temp_data_dir) / "moods.json"
        inspirations_file = Path(temp_data_dir) / "inspirations.json"
        todos_file = Path(temp_data_dir) / "todos.json"
        
        # Check records.json
        assert records_file.exists()
        with open(records_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        assert len(records) == 1
        assert records[0]["record_id"] == data["record_id"]
        assert records[0]["input_type"] == "text"
        assert records[0]["original_text"] == text_input
        
        # Check moods.json
        assert moods_file.exists()
        with open(moods_file, 'r', encoding='utf-8') as f:
            moods = json.load(f)
        assert len(moods) == 1
        assert moods[0]["type"] == "ç„¦è™‘"
        
        # Check inspirations.json
        assert inspirations_file.exists()
        with open(inspirations_file, 'r', encoding='utf-8') as f:
            inspirations = json.load(f)
        assert len(inspirations) == 1
        
        # Check todos.json
        assert todos_file.exists()
        with open(todos_file, 'r', encoding='utf-8') as f:
            todos = json.load(f)
        assert len(todos) == 2
    
    @patch("app.main.SemanticParserService")
    def test_text_workflow_with_no_data(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test text workflow when no structured data is extracted."""
        # Mock semantic parser with empty data
        from app.models import ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData())
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Make request with text
        response = test_client.post(
            "/api/process",
            data={"text": "è¿™æ˜¯ä¸€æ®µæ™®é€šçš„æ–‡æœ¬"}
        )
        
        # Verify response
        assert response.status_code == 200
        data = response.json()
        assert data["mood"] is None
        assert len(data["inspirations"]) == 0
        assert len(data["todos"]) == 0
        
        # Verify storage - only records.json should exist
        records_file = Path(temp_data_dir) / "records.json"
        moods_file = Path(temp_data_dir) / "moods.json"
        inspirations_file = Path(temp_data_dir) / "inspirations.json"
        todos_file = Path(temp_data_dir) / "todos.json"
        
        assert records_file.exists()
        assert not moods_file.exists()
        assert not inspirations_file.exists()
        assert not todos_file.exists()

    @patch("app.main.SemanticParserService")
    def test_text_workflow_with_utf8_characters(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test text workflow with various UTF-8 characters (Chinese, emoji, etc.)."""
        # Mock semantic parser
        from app.models import MoodData, ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="å¼€å¿ƒğŸ˜Š", intensity=9, keywords=["å¿«ä¹", "å¹¸ç¦"])
        ))
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Make request with UTF-8 text including emoji
        text_input = "ä»Šå¤©è¶…çº§å¼€å¿ƒğŸ˜Šï¼æ„Ÿè§‰ç‰¹åˆ«å¹¸ç¦ğŸ’–"
        response = test_client.post(
            "/api/process",
            data={"text": text_input}
        )
        
        # Verify response
        assert response.status_code == 200
        data = response.json()
        assert data["mood"]["type"] == "å¼€å¿ƒğŸ˜Š"
        
        # Verify storage preserves UTF-8
        records_file = Path(temp_data_dir) / "records.json"
        with open(records_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        assert records[0]["original_text"] == text_input
    
    @patch("app.main.SemanticParserService")
    def test_multiple_text_submissions(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test multiple text submissions accumulate in storage."""
        # Mock semantic parser
        from app.models import MoodData, ParsedData
        mock_parser = MagicMock()
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # First submission
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="å¼€å¿ƒ", intensity=8)
        ))
        response1 = test_client.post(
            "/api/process",
            data={"text": "ä»Šå¤©å¾ˆå¼€å¿ƒ"}
        )
        assert response1.status_code == 200
        
        # Second submission
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="å¹³é™", intensity=5)
        ))
        response2 = test_client.post(
            "/api/process",
            data={"text": "ç°åœ¨å¾ˆå¹³é™"}
        )
        assert response2.status_code == 200
        
        # Verify both records are stored
        records_file = Path(temp_data_dir) / "records.json"
        with open(records_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        assert len(records) == 2
        
        # Verify both moods are stored
        moods_file = Path(temp_data_dir) / "moods.json"
        with open(moods_file, 'r', encoding='utf-8') as f:
            moods = json.load(f)
        assert len(moods) == 2
        assert moods[0]["type"] == "å¼€å¿ƒ"
        assert moods[1]["type"] == "å¹³é™"


class TestErrorScenariosE2E:
    """End-to-end tests for error scenarios.
    
    Tests: é”™è¯¯åœºæ™¯çš„ç«¯åˆ°ç«¯å¤„ç†
    """
    
    def test_validation_error_no_input(self, test_client, temp_data_dir):
        """Test validation error when no input is provided."""
        response = test_client.post("/api/process")
        
        assert response.status_code == 400
        data = response.json()
        assert "error" in data
        assert "timestamp" in data
        assert "è¯·æä¾›éŸ³é¢‘æ–‡ä»¶æˆ–æ–‡æœ¬å†…å®¹" in data["error"]
        
        # Verify no files are created
        records_file = Path(temp_data_dir) / "records.json"
        assert not records_file.exists()

    def test_validation_error_both_inputs(self, test_client, temp_data_dir):
        """Test validation error when both audio and text are provided."""
        audio_data = b"fake audio"
        files = {"audio": ("test.mp3", BytesIO(audio_data), "audio/mpeg")}
        
        response = test_client.post(
            "/api/process",
            files=files,
            data={"text": "some text"}
        )
        
        assert response.status_code == 400
        data = response.json()
        assert "error" in data
        
        # Verify no files are created
        records_file = Path(temp_data_dir) / "records.json"
        assert not records_file.exists()
    
    def test_validation_error_empty_text(self, test_client, temp_data_dir):
        """Test validation error when text is empty."""
        response = test_client.post(
            "/api/process",
            data={"text": ""}
        )
        
        assert response.status_code == 400
        data = response.json()
        assert "error" in data
        # Empty string is treated as no input by FastAPI
        assert "è¯·æä¾›éŸ³é¢‘æ–‡ä»¶æˆ–æ–‡æœ¬å†…å®¹" in data["error"]
    
    def test_validation_error_unsupported_audio_format(self, test_client, temp_data_dir):
        """Test validation error for unsupported audio format."""
        audio_data = b"fake audio"
        files = {"audio": ("test.ogg", BytesIO(audio_data), "audio/ogg")}
        
        response = test_client.post("/api/process", files=files)
        
        assert response.status_code == 400
        data = response.json()
        assert "error" in data
        assert "ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼" in data["error"]
        
        # Verify no files are created
        records_file = Path(temp_data_dir) / "records.json"
        assert not records_file.exists()
    
    @patch("app.main.ASRService")
    def test_asr_error_end_to_end(
        self, 
        mock_asr_class, 
        test_client,
        temp_data_dir
    ):
        """Test end-to-end error handling when ASR service fails."""
        # Mock ASR service to raise error
        from app.asr_service import ASRServiceError
        mock_asr = MagicMock()
        mock_asr.transcribe = AsyncMock(
            side_effect=ASRServiceError("APIè¿æ¥è¶…æ—¶")
        )
        mock_asr.close = AsyncMock()
        mock_asr_class.return_value = mock_asr
        
        # Create audio file
        audio_data = b"fake audio content"
        files = {"audio": ("test.mp3", BytesIO(audio_data), "audio/mpeg")}
        
        # Make request
        response = test_client.post("/api/process", files=files)
        
        # Verify error response
        assert response.status_code == 500
        data = response.json()
        assert "error" in data
        assert "è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨" in data["error"]
        assert "timestamp" in data
        
        # Verify no files are created
        records_file = Path(temp_data_dir) / "records.json"
        assert not records_file.exists()
    
    @patch("app.main.SemanticParserService")
    def test_semantic_parser_error_end_to_end(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test end-to-end error handling when semantic parser fails."""
        # Mock semantic parser to raise error
        from app.semantic_parser import SemanticParserError
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(
            side_effect=SemanticParserError("APIè¿”å›æ ¼å¼é”™è¯¯")
        )
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Make request
        response = test_client.post(
            "/api/process",
            data={"text": "æµ‹è¯•æ–‡æœ¬"}
        )
        
        # Verify error response
        assert response.status_code == 500
        data = response.json()
        assert "error" in data
        assert "è¯­ä¹‰è§£ææœåŠ¡ä¸å¯ç”¨" in data["error"]
        assert "timestamp" in data
        
        # Verify no files are created
        records_file = Path(temp_data_dir) / "records.json"
        assert not records_file.exists()

    @patch("app.main.SemanticParserService")
    @patch("app.main.StorageService")
    def test_storage_error_end_to_end(
        self, 
        mock_storage_class,
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test end-to-end error handling when storage fails."""
        # Mock semantic parser
        from app.models import ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData())
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Mock storage service to raise error
        from app.storage import StorageError
        mock_storage = MagicMock()
        mock_storage.save_record = MagicMock(
            side_effect=StorageError("ç£ç›˜ç©ºé—´ä¸è¶³")
        )
        mock_storage_class.return_value = mock_storage
        
        # Make request
        response = test_client.post(
            "/api/process",
            data={"text": "æµ‹è¯•æ–‡æœ¬"}
        )
        
        # Verify error response
        assert response.status_code == 500
        data = response.json()
        assert "error" in data
        assert "æ•°æ®å­˜å‚¨å¤±è´¥" in data["error"]
        assert "timestamp" in data
    
    @patch("app.main.ASRService")
    @patch("app.main.SemanticParserService")
    def test_asr_empty_result_end_to_end(
        self, 
        mock_parser_class,
        mock_asr_class, 
        test_client,
        temp_data_dir
    ):
        """Test end-to-end handling when ASR returns empty text."""
        # Mock ASR service to return empty string
        mock_asr = MagicMock()
        mock_asr.transcribe = AsyncMock(return_value="")
        mock_asr.close = AsyncMock()
        mock_asr_class.return_value = mock_asr
        
        # Mock semantic parser
        from app.models import ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData())
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Create audio file
        audio_data = b"silent audio"
        files = {"audio": ("test.mp3", BytesIO(audio_data), "audio/mpeg")}
        
        # Make request
        response = test_client.post("/api/process", files=files)
        
        # Should succeed but with empty text
        assert response.status_code == 200
        data = response.json()
        
        # Verify record was saved with empty text
        records_file = Path(temp_data_dir) / "records.json"
        with open(records_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        assert len(records) == 1
        assert records[0]["original_text"] == ""


class TestConcurrentRequestsE2E:
    """End-to-end tests for concurrent request handling."""
    
    @patch("app.main.SemanticParserService")
    def test_concurrent_text_submissions(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test that concurrent requests are handled correctly and stored separately."""
        # Mock semantic parser
        from app.models import MoodData, ParsedData
        mock_parser = MagicMock()
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Simulate multiple concurrent requests
        responses = []
        for i in range(5):
            mock_parser.parse = AsyncMock(return_value=ParsedData(
                mood=MoodData(type=f"æƒ…ç»ª{i}", intensity=i+1)
            ))
            response = test_client.post(
                "/api/process",
                data={"text": f"æµ‹è¯•æ–‡æœ¬{i}"}
            )
            responses.append(response)
        
        # Verify all requests succeeded
        for response in responses:
            assert response.status_code == 200
        
        # Verify all records are stored with unique IDs
        records_file = Path(temp_data_dir) / "records.json"
        with open(records_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        assert len(records) == 5
        
        # Check all record IDs are unique
        record_ids = [r["record_id"] for r in records]
        assert len(record_ids) == len(set(record_ids))
        
        # Verify all moods are stored
        moods_file = Path(temp_data_dir) / "moods.json"
        with open(moods_file, 'r', encoding='utf-8') as f:
            moods = json.load(f)
        assert len(moods) == 5


class TestDataIntegrityE2E:
    """End-to-end tests for data integrity across the pipeline."""
    
    @patch("app.main.SemanticParserService")
    def test_record_id_consistency_across_files(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test that record_id is consistent across all JSON files."""
        # Mock semantic parser with all data types
        from app.models import MoodData, InspirationData, TodoData, ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="å¼€å¿ƒ", intensity=8),
            inspirations=[InspirationData(core_idea="æƒ³æ³•", tags=[], category="ç”Ÿæ´»")],
            todos=[TodoData(task="ä»»åŠ¡")]
        ))
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Make request
        response = test_client.post(
            "/api/process",
            data={"text": "æµ‹è¯•æ•°æ®å®Œæ•´æ€§"}
        )
        
        assert response.status_code == 200
        record_id = response.json()["record_id"]
        
        # Verify record_id is consistent across all files
        records_file = Path(temp_data_dir) / "records.json"
        moods_file = Path(temp_data_dir) / "moods.json"
        inspirations_file = Path(temp_data_dir) / "inspirations.json"
        todos_file = Path(temp_data_dir) / "todos.json"
        
        with open(records_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        assert records[0]["record_id"] == record_id
        
        with open(moods_file, 'r', encoding='utf-8') as f:
            moods = json.load(f)
        assert moods[0]["record_id"] == record_id
        
        with open(inspirations_file, 'r', encoding='utf-8') as f:
            inspirations = json.load(f)
        assert inspirations[0]["record_id"] == record_id
        
        with open(todos_file, 'r', encoding='utf-8') as f:
            todos = json.load(f)
        assert todos[0]["record_id"] == record_id
    
    @patch("app.main.SemanticParserService")
    def test_timestamp_consistency(
        self, 
        mock_parser_class, 
        test_client,
        temp_data_dir
    ):
        """Test that timestamps are consistent and properly formatted."""
        # Mock semantic parser
        from app.models import MoodData, ParsedData
        mock_parser = MagicMock()
        mock_parser.parse = AsyncMock(return_value=ParsedData(
            mood=MoodData(type="å¼€å¿ƒ", intensity=8)
        ))
        mock_parser.close = AsyncMock()
        mock_parser_class.return_value = mock_parser
        
        # Make request
        response = test_client.post(
            "/api/process",
            data={"text": "æµ‹è¯•æ—¶é—´æˆ³"}
        )
        
        assert response.status_code == 200
        timestamp = response.json()["timestamp"]
        
        # Verify timestamp format (ISO 8601 with Z suffix)
        assert timestamp.endswith("Z")
        assert "T" in timestamp
        
        # Verify timestamp is consistent in storage
        moods_file = Path(temp_data_dir) / "moods.json"
        with open(moods_file, 'r', encoding='utf-8') as f:
            moods = json.load(f)
        assert moods[0]["timestamp"] == timestamp
